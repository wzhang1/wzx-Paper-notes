FEELVOS: Fast End-to-End Embedding Learning for Video Object Segmentation
-----------------

作者：Paul Voigtlaender, Yuning Chai, Florian Schroff, Hartwig Adam, Bastian Leibe, Liang-Chieh Chen

论文链接：https://arxiv.org/abs/1902.09513

摘要: Many of the recent successful methods for video object segmentation (VOS) are overly complicated, heavily rely on fine-tuning on the first frame, and/or are slow, and are hence of limited practical use. In this work, we propose FEELVOS as a simple and fast method which does not rely on fine-tuning. In order to segment a video, for each frame FEELVOS uses a semantic pixel-wise embedding together with a global and a local matching mechanism to transfer information from the first frame and from the previous frame of the video to the current frame. In contrast to previous work, our embedding is only used as an internal guidance of a convolutional network. Our novel dynamic segmentation head allows us to train the network, including the embedding, end-to-end for the multiple object segmentation task with a cross entropy loss. We achieve a new state of the art in video object segmentation without fine-tuning on the DAVIS 2017 validation set with a J&F measure of 69.1%.
最近许多成功的视频对象分割（VOS）方法过于复杂，严重依赖于第一帧的微调和/或速度慢，因此实际应用有限。在这项工作中，我们提出了一种简单而快速的方法，不依赖于微调。为了分割视频，Feelvos对每一帧使用语义像素嵌入和全局和局部匹配机制，将信息从第一帧和视频的前一帧传输到当前帧。与之前的工作相比，我们的嵌入仅用作卷积网络的内部指导。我们的动态分割头使我们能够训练网络，包括嵌入，端到端的多目标分割任务与交叉熵损失。我们在视频对象分割方面取得了新的进展，而没有对Davis 2017验证集进行微调，j&amp;f测量值为69.1%。


论文题目：FickleNet: Weakly and Semi-supervised Semantic Image Segmentation using Stochastic Inference
--------------------------------------------

作者：Jungbeom Lee, Eunji Kim, Sungmin Lee, Jangho Lee, Sungroh Yoon

论文链接：https://arxiv.org/abs/1902.10421

摘要: The main obstacle to weakly supervised semantic image segmentation is the difficulty of obtaining pixel-level information from coarse image-level annotations. Most methods based on image-level annotations use localization maps obtained from the classifier, but these only focus on the small discriminative parts of objects and do not capture precise boundaries. FickleNet explores diverse combinations of locations on feature maps created by generic deep neural networks. It selects hidden units randomly and then uses them to obtain activation scores for image classification. FickleNet implicitly learns the coherence of each location in the feature maps, resulting in a localization map which identifies both discriminative and other parts of objects. The ensemble effects are obtained from a single network by selecting random hidden unit pairs, which means that a variety of localization maps are generated from a single image. Our approach does not require any additional training steps and only adds a simple layer to a standard convolutional neural network; nevertheless it outperforms recent comparable techniques on the Pascal VOC 2012 benchmark in both weakly and semi-supervised settings.

[Decoders对于语义分割的重要性 | CVPR 2019](https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/88967613)
----------------------------------

《An End-to-end Network for Panoptic Segmentation》：在全景分割研究领域中，旷视提出了一种新颖的端到端的全景分割模型。
----------------------------------------------------------------

论文摘要：

全景分割，是需要为图像中每个像素分配类别标签的同时，分割每个目标实例的一种分割任务。这是一个具有挑战性的研究领域，传统的方法使用两个独立的模型但二者之间不共享目标特征，这将导致模型实现的效率很低。此外，传统方法通过一种启发式方法来合成两种模型的结果，在合并过程期间无法利用足够的特征上下文信息，这就导致模型难以确定每个目标实例之间的重叠关系。为了解决这些问题，本文提出了一种新颖的端到端全景分割模型，能够有效地、高效地预测单个网络中每个目标实例及其分割结果。此外，还引入了一种新颖的空间排序模块来处理所预测的实例之间的重叠关系问题。大量的实验结果表明，所提出的方法能够在 COCO Panoptic 基准上取得了非常有前景的结果。 
