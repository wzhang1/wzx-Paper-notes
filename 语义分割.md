语义分割：
================

傅里叶变换：
---------------

[傅里叶分析之掐死教程（完整版）更新于2014.06.06](https://zhuanlan.zhihu.com/p/19763358)

卷积：
---------------

卷积的意义：加权叠加

[如何通俗易懂地解释卷积？ - 张俊博的回答 - 知乎](https://www.zhihu.com/question/22298352/answer/34267457)

“选取输入——转换输入——将转换后的输入喂给算法”就被叫做特征工程。

随着卷积神经网络的训练，卷积核为了得到有用信息，在图像或特征图谱上的滤波工作会越来越好。这个过程都是自动完成，我们只需在新数据上训练自动找出新的滤波器就行了，这也是为何卷积神经网络在图像处理中如此强大的原因。



反卷积：
---------------

反卷积（deconvolution）是指通过 计算 输出和已知输入 ，求 未知输入的过程。





discriminative loss:
----

Semantic Instance Segmentation with a Discriminative Loss Function

基于区分损失函数的语义实例分割

[GitHub 地址：](https://github.com/DavyNeven/fastSceneUnderstanding)

[论文地址：](https://arxiv.org/abs/1708.02551)

![](http://5b0988e595225.cdn.sohucs.com/images/20180416/85aa5e62fbee4b8db0f502611f8cd9d6.jpeg)





backbone:
----

ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation

一种用于实时语义分割的深度神经网络体系结构

ENet是目前实时性最快的semantic segmentation

![](https://pic3.zhimg.com/v2-b7f8d494d2777b64a999faff07effe4e_b.jpg)

![](https://pic4.zhimg.com/80/v2-870fd241940d9a8d2cb1d82537f37778_hd.jpg)


lanenet:
----

[2018.2发表出来的，文章下载地址：](https://arxiv.org/abs/1802.05591)

[github上代码：](https://github.com/MaybeShewill-CV/lanenet-lane-detection）

![](https://img-blog.csdn.net/20180608161846771)

先看下它喂进去的数据集有没有问题

输入掩模看看结果



语义分割：
============

![【总结】图像语义分割之FCN和CRF](https://zhuanlan.zhihu.com/p/22308032)

图像语义分割可以说是图像理解的基石性技术，在自动驾驶系统（具体为街景识别与理解）、无人机应用（着陆点判断）以及穿戴式设备应用中举足轻重。

介绍

图像语义分割，简单而言就是给定一张图片，对图片上的每一个像素点分类，从图像上来看，就是我们需要将实际的场景图分割成下面的分割图：

![](https://pic2.zhimg.com/80/cb5e078e5008907cb04b300369b7d621_hd.jpg)

![](https://pic4.zhimg.com/80/3adeadf2a20b0cc9cd68553a95f00552_hd.jpg)

前端使用FCN进行特征粗提取，后端使用CRF/MRF优化前端的输出，最后得到分割图。

接下来，我会从前端和后端两部分进行总结。

前端

为什么需要FCN？

我们分类使用的网络通常会在最后连接几层全连接层，它会将原来二维的矩阵（图片）压扁成一维的，从而丢失了空间信息，最后训练输出一个标量，这就是我们的分类标签。

而图像语义分割的输出需要是个分割图，且不论尺寸大小，但是至少是二维的。所以，我们需要丢弃全连接层，换上全卷积层，而这就是全卷积网络了。具体定义请参看论文：Fully Convolutional Networks for Semantic Segmentation

前端结构
FCN
此处的FCN特指Fully Convolutional Networks for Semantic Segmentation论文中提出的结构，而非广义的全卷积网络。

作者的FCN主要使用了三种技术：

卷积化（Convolutional）
上采样（Upsample）
跳跃结构（Skip Layer）
卷积化

卷积化即是将普通的分类网络，比如VGG16，ResNet50/101等网络丢弃全连接层，换上对应的卷积层即可。


![](https://pic2.zhimg.com/80/42d85c5f7ddcb3f527666b250f62f5d6_hd.jpg)

这个维度是怎么算出来的？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？



跳跃结构

（这个奇怪的名字是我翻译的，好像一般叫忽略连接结构）这个结构的作用就在于优化结果，因为如果将全卷积之后的结果直接上采样得到的结果是很粗糙的，所以作者将不同池化层的结果进行上采样之后来优化输出。具体结构如下：

![](https://pic1.zhimg.com/80/ccb6dd0a7f207134ae7690974c3e88a5_hd.jpg)

这是第一种结构，也是深度学习应用于图像语义分割的开山之作，所以得了CVPR2015的最佳论文。但是，还是有一些处理比较粗糙的地方，具体和后面对比就知道了。

SegNet/DeconvNet

这样的结构总结在这儿，只是我觉得结构上比较优雅，它得到的结果不一定比上一种好。

SegNet

![](https://pic1.zhimg.com/80/6cab0e3643d16ccab0a1bf1909813484_hd.jpg)

DeconvNet

![](https://pic3.zhimg.com/80/99f62dbfe0e39aea5674deeaa2d8363d_hd.jpg)

这样的对称结构有种自编码器的感觉在里面，先编码再解码。这样的结构主要使用了反卷积和上池化。即：

![](https://pic4.zhimg.com/80/c18522f52e930a3f83748a73a829f0ad_hd.jpg)

空洞卷积：

![](https://pic4.zhimg.com/80/766fc04b86b72f7e09d8f8ff6cb648e2_hd.jpg)

deeplab:

[](https://baijiahao.baidu.com/s?id=1595995875370065359&wfr=spider&for=pc)

[GitHub 地址](：https://github.com/sthalles/deeplab_v3)

![]()
![]()


