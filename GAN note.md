
[Generative Adversarial Nets](https://arxiv.org/pdf/1406.2661.pdf )
----

![各种GAN的结构图](https://github.com/greenfishflying/tensorflow-generative-model-collections/raw/master/assets/etc/GAN_structure.png)

[千奇百怪的GAN变体，都在这里了](https://zhuanlan.zhihu.com/p/26491601)

[GAN 进展跟踪 10 大论文，不容错过（附下载）](https://zhuanlan.zhihu.com/p/34132477)


Abstract

 提出通过一个对抗过程来评估生成模型，在对抗的过程中同时训练两个网络，一个是生成模型G用于获取数据的分布情况，另一个是区分模型D用于判断一个样本是来自训练集还是由模型G生成。训练中D目标是最大化地将原始训练样本和由G生成的样本准确区分，即二分类问题，最大化log D(x)；G则要最大化模型D出现评估错误的概率log(1 – D(G(z)))，而GAN模型没有损失函数，优化过程是一个“二元极小极大博弈（minimax two-player game）”问题。则最后达到最优解时，G可以再现训练样本的分布，而D的判断准确率为50%。
 
Advantages and disadvantages：

优：

计算量小，不需要使用马尔科夫链反复采样，也不用在学习中推论（如wake-sleep），只需要使用BP来计算梯度，并且大量的函数可以被包含到模型中。

具有一些统计上的优势，因为生成网络的参数是由样本通过梯度传播来训练的，而并不是由样本直接拷贝而来。

对抗网络生成的样本更锐利清晰，甚至对于退化的分布也一样。而基于马尔科夫链的方法需要提供有点模糊的分布以便链能够混合各种分辨率？

缺： 由模型G得到的数据分布没有一个明确的表示，没有损失函数，在过于自由不可控,训练过程中很难区分是否在向好的方向训练。而且在训练时模型D需要和模型G同步得很好，否则可能发生崩溃问题，生成器开始退化，总是生成同样的样本点，无法继续学习。当生成模型崩溃时，判别模型也会对相似的样本点指向相似的方向，训练无法继续。训练较困难。

结论与展望

一个条件生成模型p(x	c)可以由将c作为输入添加到模型G和D中得到。
学习近似推理可以通过训练辅助网络来基于x预测z，这是类似于用wake-sleep算法训练的推理网络，但该推理网络具有的优势是在训练完毕后能一个固定的生成器。

半监督学习：来自判别模型D或推论网络的特征在带标签数据有限的情况下有助于提升分类器的性能。

效率提升：通过更好的协调G和D或者在训练中采用更好的分布去采样z能够对训练起到加速作用。



cGAN:
----


为了提高训练的稳定性，另一个很自然的角度就是改变学习方法。把纯无监督的 GAN 变成半监督或者有监督的。这便可以为 GAN 的训练加上一点点束缚，或者说加上一点点目标.中提出的 Conditional Generative Adversarial Nets （CGAN）便是十分直接的模型改变，在生成模型（G）和判别模型（D）的建模中均引入 conditional variable y，这个 y 就是数据的一种 label。也因此，CGAN 可以看做把无监督的 GAN 变成有监督的模型的一种改进。这个简单直接的改进被证明非常有效，并广泛用于后续的相关工作中。

[cGANs with Projection Discriminator](https://link.zhihu.com/?target=https%3A//openreview.net/pdf%3Fid%3DByS1VpgRZ)
----

[代码](https://github.com/pfnet-research/sngan_projection)

这篇论文提出了一种新的、基于投影的方法，将有条件的信息（conditional information）纳入 GAN 的判别器。这种方法与当前的大多数条件 GAN（cGAN）的框架不同，它是通过将（嵌入的）条件向量连接到特征向量来使用条件信息。通过这样的修改，研究者在 ImageNet 的 class conditional 图像生成质量比当前最优结果显著提高，并且这是只通过一对 discriminator 和 generator 实现的。该研究还将应用扩展到超分辨率，并成功地生成了高质量的超分辨率图像。代码、生成的图像和预训练的模型可用。

![](https://pic4.zhimg.com/80/v2-0a258e964f0e06227e8d294d99e7c6bd_hd.jpg)

[High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs](https://tcwang0509.github.io/pix2pixHD/)
----

研究者提出一种多尺度的生成器和判别器架构，结合新的对抗学习目标函数。实验结果表明，条件 GAN 能够合成高分辨率、照片级逼真的图像，不需要任何手工损失或预训练的网络。

不仅如此，作者还提出了一种方法，让用户能够交互式地编辑物体的外观，大大丰富了生成的数据类型。例如，在下面的视频中，你可以发现用户能够选择更换街景中车辆的颜色和型号，给街景图增加一些树木，或者改变街道类型（例如将水泥路变成十字路）。类似地，利用语义标注图合成人脸时，给定语义标注的人脸图像，你可以选择组合人的五官，调整大小肤色，添加胡子等。

作者在文中指出，他们的方法可以扩展到其他领域，尤其是医疗图像这样缺乏预训练网络的领域。

![](https://pic1.zhimg.com/80/v2-0b181283559f38a23c2f9f8604918c34_hd.jpg)

[ StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks](https://arxiv.org/pdf/1710.10916.pdf)
----

尽管生成的敌对网络 (GANs) 在各种任务中已经取得了显著的成功，但它们仍然在生成高质量图像方面面临挑战。本文提出了一种堆叠的生成对抗网络(StackGAN)，目标是生成高分辨率的现实图像。

首先，本文提出了一个包含两阶段的生成对抗网络架构 stack GAN-v1 用于文本 - 图像合成。根据给定的文字描述，GAN 在第一阶段描绘出了物体的原始形状和颜色，产生了低分辨率的图像。在第二阶段，GAN 将第一阶段的低分辨率图像和文字描述作为输入，并以逼真的细节生成高分辨率的图像。

其次，提出了一种多阶段的生成对抗性网络架构，即 StackGAN-v2，用于有条件和无条件的生成任务。提出的 StackGAN-v2 由多个树状结构的生成器和判别器组成。树的不同分支可以生成对应于同一场景的多个尺寸的图像。通过对多个分布的联合逼近，StackGAN-v2 显示了比 StackGAN -v1 更稳定的训练结果。大量的实验证明，在生成高清图像时，文章提出的堆叠的生成对抗网络比其他现阶段表现优异的算法更具优势。文章中提出的模型如图 1 所示：

![](https://pic2.zhimg.com/80/v2-501aaae4ef82ee9fb32631ff0cd7f4d3_hd.jpg)

[PG-GAN]:(https://openreview.net/pdf?id=ByS1VpgRZ)
----

这篇论文提出了一种新的、基于投影的方法，将有条件的信息（conditional information）纳入 GAN 的判别器。这种方法与当前的大多数条件 GAN（cGAN）的框架不同，它是通过将（嵌入的）条件向量连接到特征向量来使用条件信息。通过这样的修改，研究者在 ImageNet 的 class conditional 图像生成质量比当前最优结果显著提高，并且这是只通过一对 discriminator 和 generator 实现的。该研究还将应用扩展到超分辨率，并成功地生成了高质量的超分辨率图像。代码、生成的图像和预训练的模型可用。

[代码](https://github.com/tkarras/progressive_growing_of_gans)

来自 NVIDIA Research 的 GAN 论文，提出以一种渐进增大（progressive growing）的方式训练 GAN，通过使用逐渐增大的 GAN 网络（称为 PG-GAN）和精心处理的 CelebA-HQ 数据集，实现了效果令人惊叹的生成图像。作者表示，这种方式不仅稳定了训练，GAN 生成的图像也是迄今为止质量最好的。

它的关键想法是渐进地增大生成器和鉴别器：从低分辨率开始，随着训练的进展，添加新的层对越来越精细的细节进行建模。“Progressive Growing” 指的是先训练 4x4 的网络，然后训练 8x8，不断增大，最终达到 1024x1024。这既加快了训练速度，又大大稳定了训练速度，并且生成的图像质量非常高，例如 1024×1024 的 CelebA 图像。

![](https://pic3.zhimg.com/80/v2-54cfed8187b1cf5a02c086eae17670c2_hd.jpg)


![](https://pic3.zhimg.com/80/3b6c35178f34a004368770cda3ea41cd_hd.jpg)

 LAPGAN:
 ----
 
 将 GAN 的学习过程变成了 sequential “序列式” 的。具体上，LAPGAN 采用了 Laplacian Pyramid 实现了 “序列化” ，也因此起名做 LAPGAN 。
 
 [SN-GAN](https://openreview.net/pdf?id=B1QRgziT-)
 ----
 
 Goodfellow表示，虽然GAN十分擅长于生成逼真的图像，但仅仅限于单一类型，比如一种专门生成人脸的GAN，或者一种专门生成建筑物的GAN，要用一个GAN生成ImageNet全部1000种类的图像是不可能的。但是，这篇ICLR论文做到了。
 

摘要：

生成对抗网络的研究面临的挑战之一是其训练的不稳定性。在本文中，我们提出了一种叫做“谱归一化”（spectral normalization）的新的权重归一化（weight normalization）技术，来稳定判别器的训练。这种新归一化技术计算轻巧，易于并入现有的部署当中。我们在CIFAR10，STL-10和ILSVRC2012数据集上测试了谱归一化的功效，通过实验证实了相对于那些使用此前提出的训练稳定技术训练的GAN，谱归一化GAN（SN-GAN）能够生成质量相同乃至更好的图像。
 
 简单说，论文提出了一种新的权重归一化方法，用于稳定判别器的训练。作者在论文中写道，他们的归一化方法需要调整的超参数只要一个，就是 Lipschitz 常数，而且即使不调整这个超参数，也能获得满意的性能。此外，算法实现简单，额外的计算成本很小。
 
 ![](https://pic3.zhimg.com/80/v2-96087d2c2bf93447c3760c1348bdd728_hd.jpg)
 
 SN-GAN是所有方法中唯一训练成功了的，据我们所知，这也是首次用单对判别器和生成器从ImageNet数据集生成不错图像的尝试”。
 

[GLN（2016）](https://cjmcv.github.io/deeplearning-paper-notes/fsr/fgan/2016/12/15/GLN.html)
----


 人脸幻构任务在输入图像分辨率非常小(如10x12像素等)或者在不可控的多姿态多亮度情况下具有很大的挑战性。该论文在07年的Face Hallucination: Theory and Practice中的框架上做改进，提高了精度和效率，利用全局和局部约束使人脸可以高效地被模型化，并且该网络可以进行端到端训练。从理论上，该网络可以分为两个子网络，一个根据全局约束实现了整体人脸的重构，另一个则强化了人脸特定的细节部分并约束了局部图像块的数据分布统计。使用了一个用于超分辨率重构的新损失函数，结合了与训练人脸质量的重构误差作为对抗，使输出有更好的视觉效果。实验证明该方法在数据上和视觉上都达到了最先进水平。
 
 ![](https://cjmcv.github.io/deeplearning-paper-notes/images/pdSr/gln1.png)

Global Upsampling Network (GN)
 
GN网络有两条支路并行处理，在图像上采样的支路中使用反卷积层得到一个大的平滑而缺少细节的图像，使用双线性插值矩阵去初始化反卷积层权重，允许这些权重随着训练而更新，尽管反卷积层权重会更新，但不会更新太多使输出的是正常的平滑上采样图。全局细节生成的支路由全连接层作为编码层的网络实现，在除了最后用于生成128x128的上采样全局细节的层外，每一层的特征图都接ReLU。而且这里编码层无论是上采样4倍还是8倍都采用256维，这主要是因为训练样本有限，全局特征训练容易出现过拟合。最后将上采样的网络支路和全局细节特征生成支路的输出进行拼接，得到2x128x128的张量用于LN。


Local Refinement Network (LN)


LN的结构如图所示，分别对应上采样4倍和8倍任务，分析了三个有不同层数的全卷积网络框架。在每次卷积操作时都对图像做padding保持大小一致，卷积后输入到ReLU。全称没有使用池化，并且滑动步长为1，因此网络学习到了平移不变的非线性，如图2(c)，LN通过由GN得到的平滑和细节层，加强了人脸特定的局部特征。此外，重构图的局部数据分布与高分辨率对应图像块的数据分布相吻合（例如平滑的脸颊区域和尖锐的脸部轮廓）。

[info GAN](https://blog.csdn.net/wspba/article/details/54808833)
----


GAN，Generative Adversarial Network是目前非常火也是非常有潜力的一个发展方向，原始的GAN模型存在着无约束、不可控、噪声信号z很难解释等问题，近年来，在原始GAN模型的基础上衍生出了很多种模型，如：条件——CGAN、卷积——DCGAN等等，在本博客的前几篇博文里均进行了大致的解读，本篇博文将提到的InfoGAN也是GAN的一种改进成果，甚至被OPENAI称为去年的五大突破之一。

InfoGAN的出发点是，既然 GAN 的自由度是由于仅有一个 noise z，而无法控制 GAN 如何利用这个 z。那么我们就尽量去想办法在 “如何利用 z” 上做文章。于是 ,将 z 做了拆解，认为 GAN 中生成模型（G）应该包含的 “先验” 分成两种： （1）不能再做压缩的 noise z；（2）和可解释地、有隐含意义的一组隐变量 c_1, c_2, …, c_L，简写为 c 。这里面的思想主要是，当我们学习生成图像时，图像有许多可控的有含义的维度，比如笔划的粗细、图片的光照方向等等，这些便是 c ；而剩下的不知道怎么描述的便是 z 。这样一来，[7] 实际上是希望通过拆解先验的方式，让 GAN 能学出更加 disentangled 的数据表示（representation），从而既能控制 GAN 的学习过程，又能使得学出来的结果更加具备可解释性。为了引入这个 c ，[7] 利用了互信息的建模方式，即 c 应该和生成模型 （G）基于 z 和 c 生成的图片，即 G ( z,c )，高度相关 —— 互信息大。利用这种更加细致的隐变量建模控制，infoGAN 可以说将 GAN 的发展又推动了一步。首先，它们证明了 infoGAN 中的 c 对于 GAN 的训练是有确实的帮助的，即能使得生成模型（G）学出更符合真实数据的结果。其次，他们利用 c 的天然特性，控制 c 的维度，使得 infoGAN 能控制生成的图片在某一个特定语义维度的变化。

InfoGAN是什么 

简单的讲，就是一种常见的GAN，是在普通的GAN的基础上增加Q网络，可以通过无监督学习的方式学到生成的数据的类别。

二、小故事 

小D是一个很喜欢吃饺子的姑娘，喜欢吃不同的馅的饺子，而且对于饺子的要求十分高，尤其喜欢B城的一家饺子店的饺子，但是由于长期身在A城，没有办法吃到B城的饺子。 
而她的男朋友小G和她是异地，而且恰好是在B城，是一个非常宠她的小伙子，经常为了让她吃到满意的饺子，不断的尝试制作出和B城的饺子店一模一样的饺子。在每一次做完饺子之后，都会再去买一份小D爱吃的那家店的饺子，然后不辞千里给小D送去，让小D猜测哪个是他包的饺子，哪个是饺子店的饺子。终于，起初，小D总会一下子就能够分辨出来，终于，功夫不负有心人，有一天，小D已经分不出哪个是小G做的饺子哪个是饺子店的饺子了，因为它们都一样好吃了。 
故事讲到了这里，并没有结束，哈哈，毕竟好吃的除了男朋友，总少不了好闺蜜嘛，小D的好闺蜜叫小Q，不论是三观还是喜好都和小D保持高度一致，同样也喜欢吃B城的那家店的饺子，唯一不同的是，每次吃饺子的时候，都喜欢加点醋，但是，她拥有一个超能力，那就是，虽然不同馅的饺子的外形差异很细微，但是她是他们三个中唯一一个能够分辨出不同馅的饺子的样子的差异的人，而小D和小G并做不到这一点，经常吃一口才知道是什么馅的。 
好啦，故事讲到这里，就该结束了，其他细节请见下次分享。

三、InfoGAN网络结构 

1、判别器（Discriminator） 

小D：她的作用是判别饺子店的饺子和男朋友的饺子之间是否有差异的。 

而对于InfoGAN来说，就是判断real data （x）和生成器生成的fake data (G（z）)之间的差异有多少。 

2、生成器（Generator） 

小G：他的作用是不断的提高自己的造假能力，知道他做出的不同馅的饺子小D分辨不出来是他做的还是饺子店做的为止。

而对于InfoGAN来说，生成器就是利用噪声z和latent code c来进行生成仿真的数据，直到判别器无法分辨出数据到底是来自真实的数据x还是生成的数据G（z）为止。 

3、分类器 

小Q:她的作用是为了分辨出不同馅的饺子的差异，饺子上是没有标记的。 

而对于InfoGAN来说，Q网络是和D网络公用除了最后一层之外的其他所有的层的，它是为了分辨出数据之间的类别是什么，比如什么馅的饺子。 



[SRGAN](https://cjmcv.github.io/deeplearning-paper-notes/fgan/fsr/2016/12/26/SRGAN.html)
----

论文概述：

本论文中，使用生成对抗网络GAN用于超分辨率重构。提出了一种感知损失（perceptual loss），包含有对抗损失和内容损失（content loss）。对抗损失基于鉴别器使生成图像更接近真实图像；内容损失由直观相似性（perceptual similarity）驱动而不是像素域上的相似性。文中以深度残差网络作为生成模型，以VGG网络作为鉴别器，可以从高度下采样的图像中恢复图像真实的纹理信息。大量的mean-opinion-score（MOS，平均主观意见分）测试表明使用SRGAN在视觉质量（perceptual quality）上有巨大意义。

![对比结果](https://cjmcv.github.io/deeplearning-paper-notes/images/pdGan/srgan1.png)

  对于大的上采样因子，SR通常存在纹理细节缺失的问题，如图中SRResNet的PSNR评分很高，但从服饰/叶子等可以看出，也存在细节缺失的问题。而文中提出的算法SRGAN虽然PSNR分数没有SRResNet的高，但可生成很多细节信息，使在人类视觉感官上图像质量更高。注：论中算法评价标准为MOS，而不是PSNR或SSIM。
  
  训练细节与实验结果
  
从ImageNet中随机抽取35w样本，通过双立方插值进行4倍下采样。从不同的16张图像上随机裁剪96x96的图像块作为一个mini-batch。基于MSE优化的SRResNet作为GAN的生成器初始化预训练模型以避免陷入局部最优，交替训练。在测试的时候将batch-normalization的更新关掉，使输出仅取决与输入。

[SimGAN](https://cjmcv.github.io/deeplearning-paper-notes/fgan/2017/01/08/SimGAN.html)
----

论文算法概述
   人工合成的图像和真实图像分布存在一定差异，所以直接从人工合成样本中进行训练难以达到预期的效果。为减少这个差异，论文中提出Simulated+Unsupervised (S+U) learning“模拟+无监督”学习方法，在保留从网络输出的注释信息的同时使用无标签的真实数据使simulator生成数据更接近现实。这种方法与GANs生成对抗网络相似，但这里是以合成图像作为输入，而不是GAN中的以随机向量作为输入。相对于标准的GAN，有几点关键的修改：自正则化(self-regularization)，局部对抗性损失和使用精炼图像refined images去优化鉴别器。该方法在没有使用任何标注数据的情况下在MPIIGaze数据库上达到最高水平的效果。

![](https://cjmcv.github.io/deeplearning-paper-notes/images/pdGan/simgan1.png)

 上图为SimGAN的概要图，使用一个refiner网络R来对由模拟器simulator生成的图像进行精炼(refine)，使最小化局部对抗损失(local adversarial loss)和自正则化(self regularization)。其中对抗损失迷惑用于判断图像是真实图像还是精炼图像的鉴别器D，而自正则化用于最小化生成图像和精炼图像的差异。这样保留了注释信息（如图中的视线方向），使精炼得到的图像适合于模型训练。在训练时，精炼网络R和鉴别器网络D是交替更新的。
 
 模拟+无监督学习
 
S+U学习的目的是使用无标签真实图像集去训练精炼网络R去提炼由模拟器网络得到的图像，在保留生成网络中该图像的注释信息的同时，使精炼图像看起来更像真实图像。精炼网络R的参数theta，由两个loss进行监督训练，其中xi为训练样本，xi~为相应的精炼图像，第一部分是在合成图像中增加真实性的成本，第二部分是通过最小化合成图像与精炼图像的差异来保留注释信息的成本。

根据精炼图像的历史情况去更新鉴别器

对抗训练的另一个问题是鉴别器只关注最后的精炼图像结果进行训练，这样会导致有两个问题，一个是分散了对抗训练，二是精炼器会再次引入鉴别器曾经关注过而当前没关注的人工合成信息。在训练过程中的任何时刻从精炼器中得到的精炼图像，对于鉴别器来说都属于‘假’的一类，所以鉴别器应可以把这些图像都分到‘假’一类，而不仅只针对当前生成的mini-batch个精炼图像。通过简单修改Algorithm1，使采用精炼器的历史情况来更新鉴别器。令B为由以往精炼器生成的精炼图像集的缓存，b为mini-batch大小，在鉴别器训练的每次迭代中，通过从当前精炼器中采样b/2的图像来计算鉴别器的损失函数，然后从缓存中采样额外的b/2的图像来更新参数。保持缓存B大小固定，然后在每次迭代中随机使用新生成的精炼图像去替换缓存中b/2个图像，如图4。
![](https://cjmcv.github.io/deeplearning-paper-notes/images/pdGan/simgan6.png)
