网络压缩
=====



1.主要指标有两项：
-----

1.时间代价：

训练所需时间长短和预测所需时间长短，一般训练时间可以提前准备，所以这方面并非十分重要，而预测时间则十分关键，预测时间代价决定网络在目标检测过程中能否做到实时检测。

2.空间代价：

训练的模型参数所占空间，如AlexNet拥有61M参数，需要消耗249MB的存储空间，这导致深度神经网络无法很好的在嵌入式和移动设备上投入应用。

因此，网络压缩解决是深度神经网络产业落地问题重要的一环


[2.主要方法：](https://zhuanlan.zhihu.com/p/38473604)
-----

### 网络裁枝:

将无用的参数删去

有两种方法：

1.根据损失函数对参数二阶导大小：

损失函数对参数的二阶导太小就意味着这个参数的更新对损失函数下降的贡献很小，说明这个参数不重要，故可删去。

此方法需要尽可能保证损失函数不变的情况下，对结果影响相对较小，但是计算复杂

2.根据参数绝对值大小

参数绝对值太小，说明输出与参数几乎无关，故可删去

此方法尽可能保证每层输出特征图不变，对结果影响相对较大，计算简单


### [模型量化：附带代码](https://www.jiqizhixin.com/articles/2018-06-01-11)

![](https://image.jiqizhixin.com/uploads/editor/8129d831-0961-473b-9d90-74078115a2d5/1527831867910.png)

将32位浮点数转换为整数减小储存空间

[tensorflow模型量化尝试](https://blog.csdn.net/u011961856/article/details/76736103)

[神经网络加速之量化模型（附带代码）](https://zhuanlan.zhihu.com/p/37220669)

[神经网络压缩和加速](https://zhuanlan.zhihu.com/p/27423806)

量化方法：

1.最简单的方法：

将每层中的最小值和最大值储存起来，然后将每个浮点数压缩成8位数字，将最大值和最小值的区间分成256个等级表示。

例如-3.0到6.0的范围，0字节将代表-3.0，255代表6.0，128代表约1.5。

![](https://pic2.zhimg.com/80/v2-5f5b687f34e9bf124b3586da4dbd17a6_hd.jpg)

### 低秩估计

没看懂，大意就是改变矩阵的计算方法

### 模型蒸馏:

![](https://pic4.zhimg.com/80/v2-49fe1cf3908b09ebb10d67a746213790_hd.jpg)

简而言之就是训练一个小的网络，尽量达到大网络的性能


## [ShuffleNet（Face++, 2017）](https://cjmcv.github.io/deeplearning-paper-notes/fcompress/2018/05/08/ShuffleNet.html)

[MXShuffleNet mxnet 代码](https://github.com/greenfishflying/MXShuffleNet)

[ShuffleNet pytorch代码](https://github.com/greenfishflying/ShuffleNet)

### 核心思想：

![](https://img-blog.csdn.net/20170902161241839?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmcxYmFvMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

分组交换通道的示意图，a)是不交换通道但是分成3组了，要吧看到，不同的组是完全独立的；b)每组内又分成3组，不分别交换到其它组中，这样信息就发生了交换，c)这个是与b)是等价的。

##[Deep Compression深度压缩]()

[代码](https://github.com/songhan/Deep-Compression-AlexNet)

###Network Pruning网络剪枝：

“剪枝”详细点说也可以分为3步：

（1） 进行正常的网络训练；

（2） 删除所有权重小于一定阈值的连接；

（3） 对上面得到的稀疏连接网络再训练；

###Huffman Coding哈夫曼编码：

哈夫曼编码是根据符号出现频率进行编码

优化后的代码大约减少20%的空间

![](https://pic3.zhimg.com/80/2119b0e4ab5b7a9ed293d87acc134e23_hd.jpg)


###[Squeezenet ](https://zhuanlan.zhihu.com/p/31558773)

Squeeze net 源于ALEXBNET 采用了模块化卷积，

Fire model：

![](https://pic2.zhimg.com/80/v2-28bf31dfe4fbf1a25a6e71fc4846c6e6_hd.jpg)

结构如上图

先用1* 1 卷积核降维，然后再用若干卷积核提取特征


下图为Squeezenet的结构

![](https://pic1.zhimg.com/80/v2-aeab08225db4390c2a25a1f12c57493c_hd.jpg)

####性能：

模型从240MB缩小到了4.8MB 缩小了50倍

![其他压缩方式后](https://pic1.zhimg.com/80/v2-ecd9a204dc3354e56c81e1ca11016b5b_hd.jpg)



MobileNet 结构简单微调的一点性能提升(https://www.jianshu.com/p/681960b4173d?from=groupmessage)
----

### 网络结构

![](https://upload-images.jianshu.io/upload_images/1785630-4a44f8ae38f3d1ed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/680/format/webp)

这样的结构一目了然，最右边Compact-MNet 在第一次步长为2 的卷积之后并没有"逗留"，而是径直再进入一次步长为2 的卷积，如果将depthwise + pointwise 卷积看成是一个conv set 的话，那么这个结构简单说就是网络开始就进入连续三个步长为2的conv sets。后边都是按MobileNet 照猫画虎了，期间还尝试了几个类似的high-level层的微调结构，这个是最好的一个。
这个工作的思维过程说起来还是从ShuffleNet 中学习来的，简单说就是将ShuffleNet 开始的头部结构拿到了MobileNet 上进行了一次移植。
大概猜测的原因是，这样可以迅速降低特征图分辨率，降低对等结构计算量，同时保持计算量不变的结构的特征描述能力比原版的就要好一些了。

作者：刀刀宁
链接：https://www.jianshu.com/p/681960b4173d
來源：简书
简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。


深度 | 级联MobileNet-V2实现人脸关键点检测（附训练源码）[这都可以？？？？？](http://www.sohu.com/a/225307039_129720)
----

整体框架及思路

本实验采用两级级联 MobileNet-V2，分别称之为 level_1 和 level_2，由于个人精力有限，level_1 和 level_2 采用完全相同的网络结构。level_1 进行粗略的关键点定位；依据 level_1 输出的关键点进行人脸区域裁剪，获得人脸区域图像作为 level_2 的输入，最终关键点定位信息由 level_2 进行输出。

流程如下图所示：

![](http://5b0988e595225.cdn.sohucs.com/images/20180311/e1c3c2647b984b0aac1ca5257a5999ed.jpeg)

结果：

![](http://5b0988e595225.cdn.sohucs.com/images/20180311/9eac95fb5dc148afa85b9261f427954d.jpeg)

级联检测效果如上图所示，其中，绿色点为真实 landmark，红色点为 level_1 的预测，蓝色点为 level_2 的预测。可以看到蓝色点比红色点更靠近绿色点：



