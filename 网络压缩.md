网络压缩
=====



1.主要指标有两项：
-----

1.时间代价：

训练所需时间长短和预测所需时间长短，一般训练时间可以提前准备，所以这方面并非十分重要，而预测时间则十分关键，预测时间代价决定网络在目标检测过程中能否做到实时检测。

2.空间代价：

训练的模型参数所占空间，如AlexNet拥有61M参数，需要消耗249MB的存储空间，这导致深度神经网络无法很好的在嵌入式和移动设备上投入应用。

因此，网络压缩解决是深度神经网络产业落地问题重要的一环


[2.主要方法：](https://zhuanlan.zhihu.com/p/38473604)
-----

### 网络裁枝:

将无用的参数删去

有两种方法：

1.根据损失函数对参数二阶导大小：

损失函数对参数的二阶导太小就意味着这个参数的更新对损失函数下降的贡献很小，说明这个参数不重要，故可删去。

此方法需要尽可能保证损失函数不变的情况下，对结果影响相对较小，但是计算复杂

2.根据参数绝对值大小

参数绝对值太小，说明输出与参数几乎无关，故可删去

此方法尽可能保证每层输出特征图不变，对结果影响相对较大，计算简单


### [模型量化：附带代码](https://www.jiqizhixin.com/articles/2018-06-01-11)

![](https://image.jiqizhixin.com/uploads/editor/8129d831-0961-473b-9d90-74078115a2d5/1527831867910.png)

将32位浮点数转换为整数减小储存空间

[tensorflow模型量化尝试](https://blog.csdn.net/u011961856/article/details/76736103)

[神经网络加速之量化模型（附带代码）](https://zhuanlan.zhihu.com/p/37220669)

[神经网络压缩和加速](https://zhuanlan.zhihu.com/p/27423806)

量化方法：

1.最简单的方法：

将每层中的最小值和最大值储存起来，然后将每个浮点数压缩成8位数字，将最大值和最小值的区间分成256个等级表示。

例如-3.0到6.0的范围，0字节将代表-3.0，255代表6.0，128代表约1.5。

![](https://pic2.zhimg.com/80/v2-5f5b687f34e9bf124b3586da4dbd17a6_hd.jpg)

### 低秩估计

没看懂，大意就是改变矩阵的计算方法

### 模型蒸馏:

![](https://pic4.zhimg.com/80/v2-49fe1cf3908b09ebb10d67a746213790_hd.jpg)

简而言之就是训练一个小的网络，尽量达到大网络的性能


## [ShuffleNet（Face++, 2017）](https://cjmcv.github.io/deeplearning-paper-notes/fcompress/2018/05/08/ShuffleNet.html)

[MXShuffleNet mxnet 代码](https://github.com/greenfishflying/MXShuffleNet)

[ShuffleNet pytorch代码](https://github.com/greenfishflying/ShuffleNet)

### 核心思想：

![](https://img-blog.csdn.net/20170902161241839?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmcxYmFvMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

分组交换通道的示意图，a)是不交换通道但是分成3组了，要吧看到，不同的组是完全独立的；b)每组内又分成3组，不分别交换到其它组中，这样信息就发生了交换，c)这个是与b)是等价的。

##[Deep Compression深度压缩]()

[代码](https://github.com/songhan/Deep-Compression-AlexNet)

###Network Pruning网络剪枝：

“剪枝”详细点说也可以分为3步：

（1） 进行正常的网络训练；

（2） 删除所有权重小于一定阈值的连接；

（3） 对上面得到的稀疏连接网络再训练；

###Huffman Coding哈夫曼编码：

哈夫曼编码是根据符号出现频率进行编码

优化后的代码大约减少20%的空间

![](https://pic3.zhimg.com/80/2119b0e4ab5b7a9ed293d87acc134e23_hd.jpg)
